# mlx-openai-server

[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)

> ì´ í”„ë¡œì íŠ¸ëŠ” [cubist38/mlx-openai-server](https://github.com/cubist38/mlx-openai-server) ì €ì¥ì†Œë¥¼ forkí•˜ì—¬, ì–¸ì–´ ëª¨ë¸ ê¸°ëŠ¥ì˜ ê°œì„ ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì‹¤í—˜ì ì´ë©° ì•ˆì •ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ì€ ë§í¬ì˜ ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## ì„¤ëª… (Description)
ì´ ì €ì¥ì†ŒëŠ” MLX ëª¨ë¸ì„ ìœ„í•œ OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê³ ì„±ëŠ¥ API ì„œë²„ë¥¼ í˜¸ìŠ¤íŒ…í•©ë‹ˆë‹¤. Pythonìœ¼ë¡œ ê°œë°œë˜ê³  FastAPI í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì´ ì„œë²„ëŠ” OpenAI í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ MLX ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•˜ë©° ì‚¬ìš©ì ì¹œí™”ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì„œë²„ëŠ” í–¥ìƒëœ Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸ ì§€ì›ê³¼ í•¨ê»˜ í…ìŠ¤íŠ¸, ë¹„ì „, ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.

> **ì°¸ê³ :** ì´ í”„ë¡œì íŠ¸ëŠ” Apple Siliconì— ìµœì í™”ëœ Appleì˜ í”„ë ˆì„ì›Œí¬ì¸ MLXë¥¼ í™œìš©í•˜ë¯€ë¡œ í˜„ì¬ **M ì‹œë¦¬ì¦ˆ ì¹©ì´ íƒ‘ì¬ëœ MacOS**ë§Œ ì§€ì›í•©ë‹ˆë‹¤.

## ëª©ì°¨ (Table of Contents)
- [ì£¼ìš” ê¸°ëŠ¥ (Key Features)](#ì£¼ìš”-ê¸°ëŠ¥-key-features)
- [OpenAI í˜¸í™˜ì„± (OpenAI Compatibility)](#openai-í˜¸í™˜ì„±-openai-compatibility)
- [ì§€ì›ë˜ëŠ” ëª¨ë¸ ìœ í˜• (Supported Model Types)](#ì§€ì›ë˜ëŠ”-ëª¨ë¸-ìœ í˜•-supported-model-types)
- [ì„¤ì¹˜ (Installation)](#ì„¤ì¹˜-installation)
- [ì‚¬ìš©ë²• (Usage)](#ì‚¬ìš©ë²•-usage)
  - [ì„œë²„ ì‹œì‘ (Starting the Server)](#ì„œë²„-ì‹œì‘-starting-the-server)
  - [CLI ì‚¬ìš©ë²• (CLI Usage)](#cli-ì‚¬ìš©ë²•-cli-usage)
  - [ë¡œê¹… êµ¬ì„± (Logging Configuration)](#ë¡œê¹…-êµ¬ì„±-logging-configuration)
  - [API ì‚¬ìš© (Using the API)](#api-ì‚¬ìš©-using-the-api)
  - [êµ¬ì¡°í™”ëœ ì¶œë ¥ (Structured Outputs)](#json-ìŠ¤í‚¤ë§ˆë¥¼-ì´ìš©í•œ-êµ¬ì¡°í™”ëœ-ì¶œë ¥-structured-outputs-with-json-schema)
- [ìš”ì²­ ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ (Request Queue System)](#ìš”ì²­-ëŒ€ê¸°ì—´-ì‹œìŠ¤í…œ-request-queue-system)
- [API ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (API Response Schemas)](#api-ì‘ë‹µ-ìŠ¤í‚¤ë§ˆ-api-response-schemas)
- [ì˜ˆì œ ë…¸íŠ¸ë¶ (Example Notebooks)](#ì˜ˆì œ-ë…¸íŠ¸ë¶-example-notebooks)
- [ëŒ€ê·œëª¨ ëª¨ë¸ (Large Models)](#ëŒ€ê·œëª¨-ëª¨ë¸-large-models)
- [ë¼ì´ì„ ìŠ¤ (License)](#ë¼ì´ì„ ìŠ¤-license)

---

## ì£¼ìš” ê¸°ëŠ¥ (Key Features)
- ğŸš€ MLX ëª¨ë¸ì„ ìœ„í•œ **ë¹ ë¥´ê³  ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” OpenAI í˜¸í™˜ API**
- ğŸ–¼ï¸ ë¹„ì „, ì˜¤ë””ì˜¤ ë° í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ **ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì§€ì›**
- ğŸ¨ MLX Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸(schnell, dev, Krea-dev, kontext)ì„ ì‚¬ìš©í•œ **ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘**
- ğŸ”Œ ì•±ì—ì„œ OpenAI APIë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” **ë“œë¡­ì¸(Drop-in) êµì²´**
- ğŸ“ˆ **ì„±ëŠ¥ ë° ëŒ€ê¸°ì—´ ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸**
- ğŸ§‘â€ğŸ’» **ì‰¬ìš´ Python ë° CLI ì‚¬ìš©**
- ğŸ›¡ï¸ **ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ìš”ì²­ ê´€ë¦¬**
- ğŸ›ï¸ ë¯¸ì„¸ ì¡°ì •ëœ ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ì„ ìœ„í•œ **LoRA ì–´ëŒ‘í„° ì§€ì›**
- âš¡ ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•œ **êµ¬ì„± ê°€ëŠ¥í•œ ì–‘ìí™”** (4-bit, 8-bit, 16-bit)
- ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™” ë° ì„±ëŠ¥ ì¡°ì •ì„ ìœ„í•œ **ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**

## OpenAI í˜¸í™˜ì„± (OpenAI Compatibility)

ì´ ì„œë²„ëŠ” OpenAI API ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ OpenAI ì„œë¹„ìŠ¤ì˜ ë“œë¡­ì¸ ëŒ€ì²´í’ˆìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì§€ì›í•©ë‹ˆë‹¤:
- ì±„íŒ… ì™„ì„± (ìŠ¤íŠ¸ë¦¬ë° ë° ë¹„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‘)
- ë©€í‹°ëª¨ë‹¬ ìƒí˜¸ ì‘ìš© (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë° ì˜¤ë””ì˜¤)
- Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘
- ì„ë² ë”© ìƒì„±
- í•¨ìˆ˜ í˜¸ì¶œ(Function calling) ë° ë„êµ¬ ì‚¬ìš©(Tool use)
- í‘œì¤€ OpenAI ìš”ì²­/ì‘ë‹µ í˜•ì‹
- ì¼ë°˜ì ì¸ OpenAI ë§¤ê°œë³€ìˆ˜ (temperature, top_p ë“±)

## ì§€ì›ë˜ëŠ” ëª¨ë¸ ìœ í˜• (Supported Model Types)

ì„œë²„ëŠ” 6ê°€ì§€ ìœ í˜•ì˜ MLX ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤:

1. **í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸** (`--model-type lm`) - ìˆœìˆ˜ ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•´ `mlx-lm` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
2. **ë©€í‹°ëª¨ë‹¬ ëª¨ë¸** (`--model-type multimodal`) - í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë° ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ìœ„í•´ `mlx-vlm` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
3. **ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸** (`--model-type image-generation`) - í–¥ìƒëœ êµ¬ì„±ì˜ Flux ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì„ ìœ„í•´ `mflux` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
4. **ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸** (`--model-type image-edit`) - Flux ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ì„ ìœ„í•´ `mflux` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
5. **ì„ë² ë”© ëª¨ë¸** (`--model-type embeddings`) - ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±ì„ ìœ„í•´ `mlx-embeddings` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
6. **Whisper ëª¨ë¸** (`--model-type whisper`) - ì˜¤ë””ì˜¤ ì „ì‚¬ ë° ìŒì„± ì¸ì‹ì„ ìœ„í•´ `mlx-whisper` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. âš ï¸ *ffmpeg ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.*

### Whisper ëª¨ë¸

> **âš ï¸ ì°¸ê³ :** Whisper ëª¨ë¸ì€ ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤: `brew install ffmpeg`

### Flux ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ëª¨ë¸

ì„œë²„ëŠ” ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ì„ ìœ„í•´ ì—¬ëŸ¬ Flux ë° Qwen ëª¨ë¸ êµ¬ì„±ì„ ì§€ì›í•©ë‹ˆë‹¤:

#### ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸
- **`flux-schnell`** - 4ê°œì˜ ê¸°ë³¸ ë‹¨ê³„ë¡œ ë¹ ë¥¸ ìƒì„±, ê°€ì´ë˜ìŠ¤ ì—†ìŒ (ë¹ ë¥¸ ë°˜ë³µ ì‘ì—…ì— ìµœì )
- **`flux-dev`** - 25ê°œì˜ ê¸°ë³¸ ë‹¨ê³„, 3.5 ê°€ì´ë˜ìŠ¤ë¡œ ê³ í’ˆì§ˆ ìƒì„± (í’ˆì§ˆ/ì†ë„ ê· í˜•)
- **`flux-krea-dev`** - 28ê°œì˜ ê¸°ë³¸ ë‹¨ê³„, 4.5 ê°€ì´ë˜ìŠ¤ë¡œ í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆ (ìµœê³  í’ˆì§ˆ)
- **`qwen-image`** - 50ê°œì˜ ê¸°ë³¸ ë‹¨ê³„, 4.0 ê°€ì´ë˜ìŠ¤ì˜ Qwen ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ (ê³ í’ˆì§ˆ Qwen ê¸°ë°˜ ìƒì„±)
- **`z-image-turbo`** - ë¹ ë¥¸ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ Z-Image Turbo ëª¨ë¸
- **`fibo`** - ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ Fibo ëª¨ë¸

#### ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸
- **`flux-kontext-dev`** - 28ê°œì˜ ê¸°ë³¸ ë‹¨ê³„, 2.5 ê°€ì´ë˜ìŠ¤ë¡œ ë¬¸ë§¥ ì¸ì‹ í¸ì§‘ (ë¬¸ë§¥ ì´ë¯¸ì§€ í¸ì§‘ì— íŠ¹í™”)
- **`qwen-image-edit`** - 50ê°œì˜ ê¸°ë³¸ ë‹¨ê³„, 4.0 ê°€ì´ë˜ìŠ¤ì˜ Qwen ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ (ê³ í’ˆì§ˆ Qwen ê¸°ë°˜ í¸ì§‘)

ê° êµ¬ì„±ì€ ë‹¤ìŒì„ ì§€ì›í•©ë‹ˆë‹¤:
- **ì–‘ìí™” ìˆ˜ì¤€**: ë©”ëª¨ë¦¬/ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ 4-bit, 8-bit ë˜ëŠ” 16-bit
- **LoRA ì–´ëŒ‘í„°**: ë¯¸ì„¸ ì¡°ì •ëœ ìƒì„± ë° í¸ì§‘ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ìŠ¤ì¼€ì¼ë§ì´ í¬í•¨ëœ ë‹¤ì¤‘ LoRA ê²½ë¡œ (ëª¨ë“  Flux ë° Qwen ì´ë¯¸ì§€ ëª¨ë¸ ì§€ì›).
- **ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜**: ë‹¨ê³„(Steps), ê°€ì´ë˜ìŠ¤(Guidance), ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸(Negative prompts) ë“±

### ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ êµ¬ì„± (Context Length Configuration)

ì„œë²„ëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

- **ê¸°ë³¸ ë™ì‘**: `--context-length`ê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ì„œë²„ëŠ” ëª¨ë¸ì˜ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- **ë©”ëª¨ë¦¬ ìµœì í™”**: ë” ì‘ì€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì„¤ì •í•˜ë©´ íŠ¹íˆ ëŒ€í˜• ëª¨ë¸ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ì„±ëŠ¥ ì¡°ì •**: íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì— ë”°ë¼ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
- **ì§€ì›ë˜ëŠ” ëª¨ë¸**: ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ êµ¬ì„±ì€ í…ìŠ¤íŠ¸ ì „ìš©(`lm`) ë° ë©€í‹°ëª¨ë‹¬(`multimodal`) ëª¨ë¸ ìœ í˜• ëª¨ë‘ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.
- **í”„ë¡¬í”„íŠ¸ ìºì‹±**: ì„œë²„ëŠ” ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ì§€ì •ë  ë•Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ ìºì‹±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€ ì˜ˆ:**
- **ì§§ì€ ëŒ€í™”**: ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” ë” ì‘ì€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(ì˜ˆ: 2048, 4096)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- **ë¬¸ì„œ ì²˜ë¦¬**: ê¸´ ë¬¸ì„œ ë¶„ì„ì—ëŠ” ë” í° ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(ì˜ˆ: 8192, 16384)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- **ë©”ëª¨ë¦¬ê°€ ì œí•œëœ ì‹œìŠ¤í…œ**: ì œí•œëœ RAMì— ë” í° ëª¨ë¸ì„ ë§ì¶”ë ¤ë©´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì¤„ì´ì„¸ìš”.

### ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ (Custom Chat Templates)

ì„œë²„ëŠ” ì–¸ì–´ ëª¨ë¸(`lm`) ë° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(`multimodal`)ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ì„ ì§€ì›í•©ë‹ˆë‹¤. ì±„íŒ… í…œí”Œë¦¿ì€ ëŒ€í™” ë©”ì‹œì§€ê°€ ëª¨ë¸ë¡œ ì „ì†¡ë˜ê¸° ì „ì— í˜•ì‹ì´ ì§€ì •ë˜ëŠ” ë°©ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.

**ê¸°ëŠ¥:**
- **ì‚¬ìš©ì ì •ì˜ ì„œì‹**: ëª¨ë¸ì˜ ê¸°ë³¸ ì±„íŒ… í…œí”Œë¦¿ì„ ì‚¬ìš©ì ì •ì˜ Jinja2 í…œí”Œë¦¿ìœ¼ë¡œ ë®ì–´ì”ë‹ˆë‹¤.
- **ëª¨ë¸ í˜¸í™˜ì„±**: í…ìŠ¤íŠ¸ ì „ìš© ë° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ëª¨ë‘ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.
- **íŒŒì¼ ê¸°ë°˜ êµ¬ì„±**: ì„œë²„ë¥¼ ì‹œì‘í•  ë•Œ `.jinja` í…œí”Œë¦¿ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•:**
```bash
# ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ìœ¼ë¡œ ì„œë²„ ì‹œì‘
python -m app.main \
  --model-path <path-to-model> \
  --model-type lm \
  --chat-template-file /path/to/custom_template.jinja
```

**í…œí”Œë¦¿ íŒŒì¼ í˜•ì‹:**
ì±„íŒ… í…œí”Œë¦¿ì€ Jinja2 êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ë©° í† í¬ë‚˜ì´ì €/í”„ë¡œì„¸ì„œê°€ ì˜ˆìƒí•˜ëŠ” í‘œì¤€ í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. í…œí”Œë¦¿ì€ ëŒ€í™” ê¸°ë¡ì´ í¬í•¨ëœ `messages` ë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€ ì˜ˆ:**
- **ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì„œì‹**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì‚¬ìš©ì ë©”ì‹œì§€ ë° ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ í˜•ì‹ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
- **ëª¨ë¸ë³„ ìš”êµ¬ ì‚¬í•­**: íŠ¹ì • ì„œì‹ì´ í•„ìš”í•œ ëª¨ë¸ì— ë§ê²Œ í…œí”Œë¦¿ì„ ì¡°ì •í•©ë‹ˆë‹¤.
- **íŒŒì¸ íŠœë‹ í˜¸í™˜ì„±**: íŒŒì¸ íŠœë‹ ë°ì´í„° í˜•ì‹ê³¼ ì¼ì¹˜í•˜ëŠ” í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

> **ì°¸ê³ :** ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì„œë²„ ì‹œì‘ ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ê³  íŒŒì¼ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

## ì„¤ì¹˜ (Installation)

MLX ê¸°ë°˜ ì„œë²„ë¥¼ ì„¤ì •í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:

### ì „ì œ ì¡°ê±´
- Apple Silicon (M ì‹œë¦¬ì¦ˆ) ì¹©ì´ íƒ‘ì¬ëœ MacOS
- Python 3.11 (ê¸°ë³¸ ARM ë²„ì „)
- pip íŒ¨í‚¤ì§€ ê´€ë¦¬ì

### ì„¤ì • ë‹¨ê³„
1. í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ê°€ìƒ í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤:
    ```bash
    python3.11 -m venv mlx-openai-server
    ```

2. ê°€ìƒ í™˜ê²½ì„ í™œì„±í™”í•©ë‹ˆë‹¤:
    ```bash
    source mlx-openai-server/bin/activate
    ```

3. íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:
    ```bash
    # ì˜µì…˜ 1: GitHubì—ì„œ ì§ì ‘ ì„¤ì¹˜
    pip install git+https://github.com/akirose/mlx-openai-server.git
    
    # ì˜µì…˜ 2: ë³µì œ í›„ ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜
    git clone https://github.com/akirose/mlx-openai-server.git
    cd mlx-openai-server
    pip install -e .
    ```

### Conda ì‚¬ìš© (ê¶Œì¥)

ë” ë‚˜ì€ í™˜ê²½ ê´€ë¦¬ì™€ ì•„í‚¤í…ì²˜ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ conda ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤:

1. **Conda ì„¤ì¹˜** (ì•„ì§ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°):
    ```bash
    mkdir -p ~/miniconda3
    curl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh -o ~/miniconda3/miniconda.sh
    bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
    rm ~/miniconda3/miniconda.sh
    source ~/miniconda3/bin/activate
    conda init --all
    ```

2. Python 3.11ë¡œ **ìƒˆ conda í™˜ê²½ ìƒì„±**:
    ```bash
    conda create -n mlx-server python=3.11
    conda activate mlx-server
    ```

3. **íŒ¨í‚¤ì§€ ì„¤ì¹˜**:
    ```bash
    # ì˜µì…˜ 1: GitHubì—ì„œ ì§ì ‘ ì„¤ì¹˜
    pip install git+https://github.com/akirose/mlx-openai-server.git
    
    # ì˜µì…˜ 2: ë³µì œ í›„ ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜
    git clone https://github.com/akirose/mlx-openai-server.git
    cd mlx-openai-server
    pip install -e .
    ```

### ì„ íƒì  ì¢…ì†ì„± (Optional Dependencies)

ì„œë²„ëŠ” í–¥ìƒëœ ê¸°ëŠ¥ì„ ìœ„í•´ ì„ íƒì  ì¢…ì†ì„±ì„ ì§€ì›í•©ë‹ˆë‹¤:

#### ê¸°ë³¸ ì„¤ì¹˜
```bash
pip install git+https://github.com/akirose/mlx-openai-server.git
```
**í¬í•¨ ë‚´ìš©:**
- í…ìŠ¤íŠ¸ ì „ìš© ì–¸ì–´ ëª¨ë¸ (`--model-type lm`)
- ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (`--model-type multimodal`) 
- ì„ë² ë”© ëª¨ë¸ (`--model-type embeddings`)
- ëª¨ë“  í•µì‹¬ API ì—”ë“œí¬ì¸íŠ¸ ë° ê¸°ëŠ¥

#### ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ ì§€ì›
ì„œë²„ëŠ” ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤:

**ì¶”ê°€ ê¸°ëŠ¥:**
- ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ (`--model-type image-generation`)
- ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ (`--model-type image-edit`)
- MLX Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸ ì§€ì›
- Qwen Image ëª¨ë¸ ì§€ì›
- ë¯¸ì„¸ ì¡°ì •ëœ ìƒì„± ë° í¸ì§‘ì„ ìœ„í•œ LoRA ì–´ëŒ‘í„° ì§€ì›

#### Whisper ëª¨ë¸ ì§€ì›
Whisper ëª¨ë¸ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë ¤ë©´ ffmpegë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
# Homebrewë¥¼ ì‚¬ìš©í•˜ì—¬ ffmpeg ì„¤ì¹˜
brew install ffmpeg
```

**ffmpeg í¬í•¨ ê¸°ëŠ¥:**
- ì˜¤ë””ì˜¤ ì „ì‚¬ ëª¨ë¸ (`--model-type whisper`)
- ìŒì„± ì¸ì‹ ê¸°ëŠ¥
- ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ í˜•ì‹ ì§€ì› (WAV, MP3, M4A ë“±)

> **ì°¸ê³ :** Whisper ëª¨ë¸ì€ ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ ffmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. whisper ëª¨ë¸ ìœ í˜•ì„ ì‚¬ìš©í•˜ê¸° ì „ì— ì„¤ì¹˜í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

### ë¬¸ì œ í•´ê²°
**ë¬¸ì œ:** OS ë° Python ë²„ì „ì´ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•˜ì§€ë§Œ `pip`ê°€ ì¼ì¹˜í•˜ëŠ” ë°°í¬íŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**ì›ì¸:** ë„¤ì´í‹°ë¸Œê°€ ì•„ë‹Œ Python ë²„ì „ì„ ì‚¬ìš©í•˜ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”:
```bash
python -c "import platform; print(platform.processor())"
```
ì¶œë ¥ì´ `i386` (M ì‹œë¦¬ì¦ˆ ë¨¸ì‹ ì—ì„œ)ì´ë©´ ë„¤ì´í‹°ë¸Œê°€ ì•„ë‹Œ Pythonì„ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤. ë„¤ì´í‹°ë¸Œ Python ë²„ì „ìœ¼ë¡œ ì „í™˜í•˜ì„¸ìš”. ì¢‹ì€ ë°©ë²•ì€ [Conda](https://stackoverflow.com/questions/65415996/how-to-specify-the-architecture-or-platform-for-a-new-conda-environment-apple)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ì‚¬ìš©ë²• (Usage)

### ì„œë²„ ì‹œì‘ (Starting the Server)

Python ëª¨ë“ˆ ë˜ëŠ” CLI ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ MLX ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë°©ë²• ëª¨ë‘ ë¡œê¹… êµ¬ì„± ì˜µì…˜ì„ í¬í•¨í•œ ë™ì¼í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

#### ë°©ë²• 1: Python ëª¨ë“ˆ
```bash
# í…ìŠ¤íŠ¸ ì „ìš© ë˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ê²½ìš°
python -m app.main \
  --model-path <path-to-mlx-model> \
  --model-type <lm|multimodal> \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100

# ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ê²½ìš° (Flux ì‹œë¦¬ì¦ˆ, Qwen, Z-Image Turbo ë˜ëŠ” Fibo)
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-model> \
  --config-name <flux-schnell|flux-dev|flux-krea-dev|qwen-image|z-image-turbo|fibo> \
  --quantize <4|8|16> \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100

# ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ì˜ ê²½ìš° (Flux ì‹œë¦¬ì¦ˆ ë˜ëŠ” Qwen)
python -m app.main \
  --model-type image-edit \
  --model-path <path-to-local-model> \
  --config-name <flux-kontext-dev|qwen-image-edit> \
  --quantize <4|8|16> \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100

# ì„ë² ë”© ëª¨ë¸ì˜ ê²½ìš°
python -m app.main \
  --model-type embeddings \
  --model-path <embeddings-model-path> \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100

# Whisper ëª¨ë¸ì˜ ê²½ìš°
python -m app.main \
  --model-type whisper \
  --model-path <whisper-model-path> \
  --max-concurrency 1 \
  --queue-timeout 600 \
  --queue-size 50

# ë¡œê¹… êµ¬ì„± ì˜µì…˜ í¬í•¨
python -m app.main \
  --model-path <path-to-mlx-model> \
  --model-type lm \
  --no-log-file \
  --log-level INFO

python -m app.main \
  --model-path <path-to-mlx-model> \
  --model-type lm \
  --log-file /tmp/custom.log \
  --log-level DEBUG
```

#### ì„œë²„ ë§¤ê°œë³€ìˆ˜
- `--model-path`: MLX ëª¨ë¸ ë””ë ‰í„°ë¦¬ ê²½ë¡œ(ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” Hugging Face ëª¨ë¸ ì €ì¥ì†Œ). `lm`, `multimodal`, `embeddings`, `image-generation`, `image-edit`, `whisper` ëª¨ë¸ ìœ í˜•ì— í•„ìš”í•©ë‹ˆë‹¤.
- `--model-type`: ì‹¤í–‰í•  ëª¨ë¸ ìœ í˜•:
  - í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ì˜ ê²½ìš° `lm`
  - ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(í…ìŠ¤íŠ¸, ë¹„ì „, ì˜¤ë””ì˜¤)ì˜ ê²½ìš° `multimodal`
  - ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ê²½ìš° `image-generation`
  - ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ì˜ ê²½ìš° `image-edit`
  - ì„ë² ë”© ëª¨ë¸ì˜ ê²½ìš° `embeddings`
  - Whisper ëª¨ë¸(ì˜¤ë””ì˜¤ ì „ì‚¬)ì˜ ê²½ìš° `whisper`
  - ê¸°ë³¸ê°’: `lm`
- `--context-length`: ì–¸ì–´ ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´. í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”ë¥¼ ìœ„í•œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’: `None` (ëª¨ë¸ì˜ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì‚¬ìš©).
- `--config-name`: ì‚¬ìš©í•  ëª¨ë¸ êµ¬ì„±. `image-generation` ë° `image-edit` ëª¨ë¸ ìœ í˜•ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤:
  - `image-generation`ì˜ ê²½ìš°: `flux-schnell`, `flux-dev`, `flux-krea-dev`, `qwen-image`, `z-image-turbo`, `fibo`
  - `image-edit`ì˜ ê²½ìš°: `flux-kontext-dev`, `qwen-image-edit`
  - ê¸°ë³¸ê°’: image-generationì˜ ê²½ìš° `flux-schnell`, image-editì˜ ê²½ìš° `flux-kontext-dev`
- `--quantize`: Flux ëª¨ë¸ì˜ ì–‘ìí™” ìˆ˜ì¤€. ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: `4`, `8`, `16`. ê¸°ë³¸ê°’: `8`
- `--lora-paths`: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ LoRA ì–´ëŒ‘í„° íŒŒì¼ ê²½ë¡œ.
- `--lora-scales`: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ LoRA ì–´ëŒ‘í„° ìŠ¤ì¼€ì¼ íŒ©í„°. LoRA ê²½ë¡œ ìˆ˜ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
- `--max-concurrency`: ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜ (ê¸°ë³¸ê°’: 1)
- `--queue-timeout`: ìš”ì²­ ì‹œê°„ ì´ˆê³¼(ì´ˆ) (ê¸°ë³¸ê°’: 300)
- `--queue-size`: ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì˜ ìµœëŒ€ ëŒ€ê¸°ì—´ í¬ê¸° (ê¸°ë³¸ê°’: 100)
- `--port`: ì„œë²„ë¥¼ ì‹¤í–‰í•  í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)
- `--host`: ì„œë²„ë¥¼ ì‹¤í–‰í•  í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)
- `--disable-auto-resize`: ìë™ ëª¨ë¸ í¬ê¸° ì¡°ì •ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤. Vision Language Modelsì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.
- `--enable-auto-tool-choice`: ìë™ ë„êµ¬ ì„ íƒ(Auto tool choice)ì„ í™œì„±í™”í•©ë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸(`lm` ë˜ëŠ” `multimodal` ëª¨ë¸ ìœ í˜•)ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.
- `--tool-call-parser`: ìë™ ê°ì§€ ëŒ€ì‹  ì‚¬ìš©í•  ë„êµ¬ í˜¸ì¶œ íŒŒì„œ(Tool call parser)ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸(`lm` ë˜ëŠ” `multimodal` ëª¨ë¸ ìœ í˜•)ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: `qwen3`, `glm4_moe`, `qwen3_moe`, `qwen3_next`, `qwen3_vl`, `harmony`, `minimax`.
- `--reasoning-parser`: ìë™ ê°ì§€ ëŒ€ì‹  ì‚¬ìš©í•  ì¶”ë¡  íŒŒì„œ(Reasoning parser)ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸(`lm` ë˜ëŠ” `multimodal` ëª¨ë¸ ìœ í˜•)ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: `qwen3`, `glm4_moe`, `qwen3_moe`, `qwen3_next`, `qwen3_vl`, `harmony`, `minimax`.
- `--trust-remote-code`: ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ `trust_remote_code`ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ ì €ì¥ì†Œì—ì„œ ì‚¬ìš©ì ì •ì˜ ì½”ë“œë¥¼ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’: `False` (ë¹„í™œì„±í™”ë¨). `lm` ë˜ëŠ” `multimodal` ëª¨ë¸ ìœ í˜•ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.
- `--chat-template-file`: ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ì˜ ê²½ë¡œì…ë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸(`lm`) ë° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(`multimodal`)ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’: `None` (ëª¨ë¸ì˜ ê¸°ë³¸ ì±„íŒ… í…œí”Œë¦¿ ì‚¬ìš©).
- `--log-file`: ë¡œê·¸ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ 'logs/app.log'ì— ë¡œê·¸ê°€ ê¸°ë¡ë©ë‹ˆë‹¤.
- `--no-log-file`: íŒŒì¼ ë¡œê¹…ì„ ì™„ì „íˆ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤. ì½˜ì†” ì¶œë ¥ë§Œ í‘œì‹œë©ë‹ˆë‹¤.
- `--log-level`: ë¡œê¹… ìˆ˜ì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì„ íƒ ì‚¬í•­: `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`. ê¸°ë³¸ê°’: `INFO`.

### íŒŒì„œ êµ¬ì„± (Parser Configuration)

ì„œë²„ëŠ” ë„êµ¬ í˜¸ì¶œ ë° ì¶”ë¡ /ìƒê°(thinking) ë‚´ìš© ì¶”ì¶œì„ ìœ„í•œ íŒŒì„œì˜ ìˆ˜ë™ êµ¬ì„±ì„ ì§€ì›í•©ë‹ˆë‹¤. íŒŒì„œê°€ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ `None`ì´ ë˜ë©°, ì´ëŠ” íŒŒì‹±ì´ ìˆ˜í–‰ë˜ì§€ ì•ŠìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

#### ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì„œ

ë‹¤ìŒ íŒŒì„œëŠ” ë„êµ¬ í˜¸ì¶œ ë° ì¶”ë¡  íŒŒì‹± ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **`qwen3`**: Qwen3 ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ
- **`glm4_moe`**: GLM4 MoE ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ
- **`qwen3_moe`**: Qwen3 MoE ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ
- **`qwen3_next`**: Qwen3 Next ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ
- **`qwen3_vl`**: Qwen3 Vision-Language ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ
- **`harmony`**: Harmony/GPT-OSS ëª¨ë¸ìš© í†µí•© íŒŒì„œ (thinkingê³¼ tools ëª¨ë‘ ì²˜ë¦¬)
- **`minimax`**: MiniMax ëª¨ë¸ í˜•ì‹ìš© íŒŒì„œ

#### íŒŒì„œ ë§¤ê°œë³€ìˆ˜

- **`--tool-call-parser`**: ëª¨ë¸ ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œì„ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©í•  íŒŒì„œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
- **`--reasoning-parser`**: ëª¨ë¸ ì‘ë‹µì—ì„œ ì¶”ë¡ /ìƒê° ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©í•  íŒŒì„œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
- **`--enable-auto-tool-choice`**: ë„êµ¬ í˜¸ì¶œ ì‚¬ìš© ì‹œ ìë™ ë„êµ¬ ì„ íƒì„ í™œì„±í™”í•©ë‹ˆë‹¤.

#### ì‚¬ìš© ì˜ˆ

**íŒŒì„œê°€ ì—†ëŠ” ê¸°ë³¸ ì‚¬ìš© (ê¸°ë³¸ê°’):**
```bash
python -m app.main launch \
  --model-path /path/to/model \
  --model-type lm
```

**ë„êµ¬ í˜¸ì¶œ íŒŒì„œë§Œ ì‚¬ìš©:**
```bash
python -m app.main launch \
  --model-path /path/to/model \
  --model-type lm \
  --tool-call-parser qwen3
```

**ë‘ íŒŒì„œ ëª¨ë‘ ì‚¬ìš©:**
```bash
python -m app.main launch \
  --model-path /path/to/model \
  --model-type lm \
  --tool-call-parser qwen3 \
  --reasoning-parser qwen3
```

**ìë™ ë„êµ¬ ì„ íƒ í™œì„±í™”:**
```bash
python -m app.main launch \
  --model-path /path/to/model \
  --model-type lm \
  --enable-auto-tool-choice \
  --tool-call-parser qwen3 \
  --reasoning-parser qwen3
```

**Harmony íŒŒì„œ ì‚¬ìš© (í†µí•© íŒŒì„œ):**
```bash
python -m app.main launch \
  --model-path /path/to/model \
  --model-type lm \
  --reasoning-parser harmony \
  --tool-call-parser harmony
```

> **ì°¸ê³ :** íŒŒì„œ êµ¬ì„±ì€ ì–¸ì–´ ëª¨ë¸(`lm` ë˜ëŠ” `multimodal` ëª¨ë¸ ìœ í˜•)ì—ë§Œ ì ìš©ë©ë‹ˆë‹¤. íŒŒì„œë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì„œë²„ëŠ” íŒŒì‹±ì„ ìˆ˜í–‰í•˜ì§€ ì•Šìœ¼ë©° ì›ì‹œ ëª¨ë¸ ì‘ë‹µì´ ë°˜í™˜ë©ë‹ˆë‹¤.

#### êµ¬ì„± ì˜ˆ

**í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸:**
```bash
python -m app.main \
  --model-path mlx-community/gemma-3-4b-it-4bit \
  --model-type lm \
  --context-length 8192 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

**ë©€í‹°ëª¨ë‹¬ ëª¨ë¸:**
```bash
python -m app.main \
  --model-path mlx-community/llava-phi-3-vision-4bit \
  --model-type multimodal \
  --context-length 4096 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

**trust_remote_codeê°€ í™œì„±í™”ëœ ëª¨ë¸:**
```bash
python -m app.main \
  --model-path <path-to-model-requiring-custom-code> \
  --model-type lm \
  --trust-remote-code \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

**ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ì´ ìˆëŠ” ëª¨ë¸:**
```bash
python -m app.main \
  --model-path <path-to-model> \
  --model-type lm \
  --chat-template-file /path/to/custom_template.jinja \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

**ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸:**

*Schnellë¡œ ë¹ ë¥¸ ìƒì„±:*
```bash
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-flux-model> \
  --config-name flux-schnell \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*Devë¡œ ê³ í’ˆì§ˆ ìƒì„±:*
```bash
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-flux-model> \
  --config-name flux-dev \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*Krea-Devë¡œ í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆ ìƒì„±:*
```bash
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-flux-model> \
  --config-name flux-krea-dev \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*Qwen Imageë¡œ ê³ í’ˆì§ˆ ìƒì„±:*
```bash
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-qwen-model> \
  --config-name qwen-image \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*Z-Image Turboë¡œ ë¹ ë¥¸ ìƒì„±:*
```bash
python -m app.main launch --model-path z-image-turbo --model-type image-generation --config-name z-image-turbo
```

*Fiboë¡œ ìƒì„±:*
```bash
python -m app.main launch --model-path fibo --model-type image-generation --config-name fibo
```

*Kontextë¡œ ì´ë¯¸ì§€ í¸ì§‘:*
```bash
python -m app.main \
  --model-type image-edit \
  --model-path <path-to-local-flux-model> \
  --config-name flux-kontext-dev \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*Qwen Image Editìœ¼ë¡œ ì´ë¯¸ì§€ í¸ì§‘:*
```bash
python -m app.main \
  --model-type image-edit \
  --model-path <path-to-local-qwen-model> \
  --config-name qwen-image-edit \
  --quantize 8 \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*LoRA ì–´ëŒ‘í„° í¬í•¨ (ì´ë¯¸ì§€ ìƒì„±):*
```bash
python -m app.main \
  --model-type image-generation \
  --model-path <path-to-local-flux-model> \
  --config-name flux-dev \
  --quantize 8 \
  --lora-paths "/path/to/lora1.safetensors,/path/to/lora2.safetensors" \
  --lora-scales "0.8,0.6" \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

*LoRA ì–´ëŒ‘í„° í¬í•¨ (ì´ë¯¸ì§€ í¸ì§‘):*
```bash
python -m app.main \
  --model-type image-edit \
  --model-path <path-to-local-flux-model> \
  --config-name flux-kontext-dev \
  --quantize 8 \
  --lora-paths "/path/to/lora1.safetensors,/path/to/lora2.safetensors" \
  --lora-scales "0.8,0.6" \
  --max-concurrency 1 \
  --queue-timeout 300 \
  --queue-size 100
```

**Whisper ëª¨ë¸:**

*Whisperë¡œ ì˜¤ë””ì˜¤ ì „ì‚¬:*
```bash
python -m app.main \
  --model-type whisper \
  --model-path mlx-community/whisper-large-v3-mlx \
  --max-concurrency 1 \
  --queue-timeout 600 \
  --queue-size 50
```

### CLI ì‚¬ìš©ë²• (CLI Usage)

ì„œë²„ëŠ” ì‰¬ìš´ ì‹œì‘ ë° ê´€ë¦¬ë¥¼ ìœ„í•œ í¸ë¦¬í•œ CLI ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

**ë²„ì „ ë° ë„ì›€ë§ í™•ì¸:**
```bash
python -m app.main --version
python -m app.main --help
python -m app.main launch --help
```

**ì„œë²„ ì‹œì‘:**
```bash
# í…ìŠ¤íŠ¸ ì „ìš© ë˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ê²½ìš°
python -m app.main launch --model-path <path-to-mlx-model> --model-type <lm|multimodal> --context-length 8192

# ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ê²½ìš° (Flux ì‹œë¦¬ì¦ˆ, Qwen, Z-Image Turbo ë˜ëŠ” Fibo)
python -m app.main launch --model-type image-generation --model-path <path-to-local-model> --config-name <flux-schnell|flux-dev|flux-krea-dev|qwen-image|z-image-turbo|fibo>

# ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ì˜ ê²½ìš° (Flux ì‹œë¦¬ì¦ˆ ë˜ëŠ” Qwen)
python -m app.main launch --model-type image-edit --model-path <path-to-local-model> --config-name <flux-kontext-dev|qwen-image-edit>

# Whisper ëª¨ë¸ì˜ ê²½ìš°
python -m app.main launch --model-path mlx-community/whisper-large-v3-mlx --model-type whisper

# LoRA ì–´ëŒ‘í„° í¬í•¨ (ì´ë¯¸ì§€ ìƒì„±)
python -m app.main launch --model-type image-generation --model-path <path-to-local-flux-model> --config-name flux-dev --lora-paths "/path/to/lora1.safetensors,/path/to/lora2.safetensors" --lora-scales "0.8,0.6"

# LoRA ì–´ëŒ‘í„° í¬í•¨ (ì´ë¯¸ì§€ í¸ì§‘)
python -m app.main launch --model-type image-edit --model-path <path-to-local-flux-model> --config-name flux-kontext-dev --lora-paths "/path/to/lora1.safetensors,/path/to/lora2.safetensors" --lora-scales "0.8,0.6"

# ì‚¬ìš©ì ì •ì˜ ë¡œê¹… êµ¬ì„± í¬í•¨
python -m app.main launch --model-path <path-to-mlx-model> --model-type lm --log-file /tmp/server.log --log-level DEBUG

# íŒŒì¼ ë¡œê¹… ë¹„í™œì„±í™” (ì½˜ì†”ë§Œ)
python -m app.main launch --model-path <path-to-mlx-model> --model-type lm --no-log-file

# ê¸°ë³¸ ë¡œê¹… ì‚¬ìš© (logs/app.log, INFO ë ˆë²¨)
python -m app.main launch --model-path <path-to-mlx-model> --model-type lm

# ë„êµ¬ í˜¸ì¶œ ë° ì¶”ë¡ ì„ ìœ„í•œ íŒŒì„œ êµ¬ì„± í¬í•¨
python -m app.main launch \
  --model-path <path-to-mlx-model> \
  --model-type lm \
  --enable-auto-tool-choice \
  --tool-call-parser qwen3 \
  --reasoning-parser qwen3

# trust_remote_code í™œì„±í™” (ì‚¬ìš©ì ì •ì˜ ì½”ë“œê°€ í•„ìš”í•œ ëª¨ë¸ìš©)
python -m app.main launch \
  --model-path <path-to-mlx-model> \
  --model-type lm \
  --trust-remote-code

# ì‚¬ìš©ì ì •ì˜ ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ ì‚¬ìš©
python -m app.main launch \
  --model-path <path-to-mlx-model> \
  --model-type lm \
  --chat-template-file /path/to/custom_template.jinja

# python -m app.main ì‚¬ìš© (ëŒ€ì²´ ë°©ë²•)
python -m app.main --model-path <path-to-mlx-model> --model-type lm --no-log-file
python -m app.main --model-path <path-to-mlx-model> --model-type lm --log-file /tmp/custom.log
python -m app.main --model-path <path-to-mlx-model> --model-type lm --trust-remote-code
python -m app.main --model-path <path-to-mlx-model> --model-type lm --chat-template-file /path/to/custom_template.jinja
```

> **ì°¸ê³ :** ì´ì œ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸(`--model-type lm`)ê³¼ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(`--model-type multimodal`) ëª¨ë‘ì—ì„œ `/v1/embeddings` ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë¡œê¹… êµ¬ì„± (Logging Configuration)

ì„œë²„ëŠ” MLX ì„œë²„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ìœ ì—°í•œ ë¡œê¹… ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤:

#### ë¡œê¹… ì˜µì…˜

- **`--log-file`**: ë¡œê·¸ íŒŒì¼ì˜ ì‚¬ìš©ì ì •ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
  - ê¸°ë³¸ê°’: `logs/app.log`
  - ì˜ˆ: `--log-file /tmp/my-server.log`

- **`--no-log-file`**: íŒŒì¼ ë¡œê¹…ì„ ì™„ì „íˆ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
  - ì½˜ì†” ì¶œë ¥ë§Œ í‘œì‹œë©ë‹ˆë‹¤.
  - ê°œë°œ ì¤‘ì´ê±°ë‚˜ ì˜êµ¬ ë¡œê·¸ê°€ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

- **`--log-level`**: ë¡œê¹…ì˜ ìƒì„¸ë„ë¥¼ ì œì–´í•©ë‹ˆë‹¤.
  - ì„ íƒ ì‚¬í•­: `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`
  - ê¸°ë³¸ê°’: `INFO`
  - `DEBUG`: ê°€ì¥ ìƒì„¸í•˜ë©° ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
  - `INFO`: í‘œì¤€ ì‘ë™ ë©”ì‹œì§€ (ê¸°ë³¸ê°’)
  - `WARNING`: ì ì¬ì ì¸ ë¬¸ì œì— ëŒ€í•œ ì¤‘ìš” ì•Œë¦¼
  - `ERROR`: ì˜¤ë¥˜ ë©”ì‹œì§€ë§Œ í‘œì‹œ
  - `CRITICAL`: ì¹˜ëª…ì ì¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë§Œ í‘œì‹œ

#### ë¡œê¹… ì˜ˆì‹œ

```bash
# ê¸°ë³¸ ë¡œê¹… ì‚¬ìš© (logs/app.log, INFO ë ˆë²¨)
python -m app.main launch --model-path <path-to-model> --model-type lm

# ë””ë²„ê·¸ ë ˆë²¨ë¡œ ì‚¬ìš©ì ì •ì˜ ë¡œê·¸ íŒŒì¼ ì‚¬ìš©
python -m app.main launch --model-path <path-to-model> --model-type lm --log-file /tmp/debug.log --log-level DEBUG

# ì½˜ì†” ì „ìš© ë¡œê¹… (íŒŒì¼ ì¶œë ¥ ì—†ìŒ)
python -m app.main launch --model-path <path-to-model> --model-type lm --no-log-file

# ê³ ìˆ˜ì¤€ ë¡œê¹… (ì˜¤ë¥˜ë§Œ)
python -m app.main launch --model-path <path-to-model> --model-type lm --log-level ERROR

# ë¡œê¹… ì˜µì…˜ê³¼ í•¨ê»˜ python -m app.main ì‚¬ìš©
python -m app.main --model-path <path-to-model> --model-type lm --no-log-file
python -m app.main --model-path <path-to-model> --model-type lm --log-file /tmp/custom.log --log-level DEBUG
```

#### ë¡œê·¸ íŒŒì¼ ê¸°ëŠ¥

- **ìë™ íšŒì „**: ë¡œê·¸ íŒŒì¼ì€ 500MBì— ë„ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ íšŒì „ë©ë‹ˆë‹¤.
- **ë³´ì¡´**: ë¡œê·¸ íŒŒì¼ì€ ê¸°ë³¸ì ìœ¼ë¡œ 10ì¼ ë™ì•ˆ ë³´ê´€ë©ë‹ˆë‹¤.
- **ì„œì‹ ìˆëŠ” ì¶œë ¥**: ì½˜ì†” ë° íŒŒì¼ ë¡œê·¸ ëª¨ë‘ íƒ€ì„ìŠ¤íƒ¬í”„, ë¡œê·¸ ìˆ˜ì¤€ ë° êµ¬ì¡°í™”ëœ í˜•ì‹ì„ í¬í•¨í•©ë‹ˆë‹¤.
- **ìƒ‰ìƒí™”ëœ ì½˜ì†”**: ì½˜ì†” ì¶œë ¥ì—ëŠ” ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìƒ‰ìƒ ì½”ë”©ì´ í¬í•¨ë©ë‹ˆë‹¤.

### API ì‚¬ìš© (Using the API)

ì„œë²„ëŠ” í‘œì¤€ OpenAI í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒì€ ëª‡ ê°€ì§€ ì˜ˆì…ë‹ˆë‹¤:

#### í…ìŠ¤íŠ¸ ì™„ì„± (Text Completion)
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"  # ë¡œì»¬ ì„œë²„ì—ëŠ” API í‚¤ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
)

response = client.chat.completions.create(
    model="local-model",  # ë¡œì»¬ ì„œë²„ì˜ ê²½ìš° ëª¨ë¸ ì´ë¦„ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    messages=[
        {"role": "user", "content": "What is the capital of France?"}
    ],
    temperature=0.7
)
print(response.choices[0].message.content)
```

#### ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (ë¹„ì „ + ì˜¤ë””ì˜¤)
```python
import openai
import base64

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ì´ë¯¸ì§€ ë¡œë“œ ë° ì¸ì½”ë”©
with open("image.jpg", "rb") as image_file:
    base64_image = base64.b64encode(image_file.read()).decode('utf-8')

response = client.chat.completions.create(
    model="local-multimodal",  # ë¡œì»¬ ì„œë²„ì˜ ê²½ìš° ëª¨ë¸ ì´ë¦„ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "What's in this image?"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]
)
print(response.choices[0].message.content)
```

#### ì˜¤ë””ì˜¤ ì…ë ¥ ì§€ì›
```python
import openai
import base64

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ì¸ì½”ë”©
with open("audio.wav", "rb") as audio_file:
    audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')

response = client.chat.completions.create(
    model="local-multimodal",  # ë¡œì»¬ ì„œë²„ì˜ ê²½ìš° ëª¨ë¸ ì´ë¦„ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "What's in this audio?"
                },
                {
                    "type": "input_audio",
                    "input_audio": {
                        "data": audio_base64,
                        "format": "wav"
                    },
                },
            ],
        }
    ],
    max_tokens=64,
)
print(response.choices[0].message.content)
```

#### Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„±

```python
import openai
import base64
from io import BytesIO
from PIL import Image

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±
response = client.images.generate(
    prompt="A serene landscape with mountains and a lake at sunset",
    model="local-image-generation-model",
    size="1024x1024",
    n=1
)

# ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ
image_data = base64.b64decode(response.data[0].b64_json)
image = Image.open(BytesIO(image_data))
image.show()
```

#### ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„±
```python
import requests

# ë” ë§ì€ ì œì–´ë¥¼ ìœ„í•´ ì§ì ‘ API í˜¸ì¶œ ì‚¬ìš©
payload = {
    "prompt": "A beautiful cyberpunk city at night with neon lights",
    "model": "local-image-generation-model",
    "size": "1024x1024",
    "negative_prompt": "blurry, low quality, distorted",
    "steps": 8,
    "seed": 42,
    "priority": "normal"
}

response = requests.post(
    "http://localhost:8000/v1/images/generations",
    json=payload,
    headers={"Authorization": "Bearer fake-api-key"}
)

if response.status_code == 200:
    result = response.json()
    # base64 ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
    image_data = base64.b64decode(result['data'][0]['b64_json'])
    image = Image.open(BytesIO(image_data))
    image.show()
```

**ì´ë¯¸ì§€ ìƒì„± ë§¤ê°œë³€ìˆ˜:**
- `prompt`: ì›í•˜ëŠ” ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª… (í•„ìˆ˜, ìµœëŒ€ 1000ì)
- `model`: ëª¨ë¸ ì‹ë³„ì (ê¸°ë³¸ê°’ "local-image-generation-model")
- `size`: ì´ë¯¸ì§€ í¬ê¸° - "256x256", "512x512" ë˜ëŠ” "1024x1024" (ê¸°ë³¸ê°’: "1024x1024")
- `negative_prompt`: ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ í”¼í•´ì•¼ í•  ê²ƒ (ì„ íƒ ì‚¬í•­)
- `steps`: ì¶”ë¡  ë‹¨ê³„ ìˆ˜, 1-50 (êµ¬ì„±ì— ë”°ë¼ ê¸°ë³¸ê°’ ë‹¤ë¦„: Schnellì˜ ê²½ìš° 4, Devì˜ ê²½ìš° 25, Krea-Devì˜ ê²½ìš° 28, Qwen Imageì˜ ê²½ìš° 50)
- `seed`: ì¬í˜„ ê°€ëŠ¥í•œ ìƒì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ (ì„ íƒ ì‚¬í•­)
- `priority`: ì‘ì—… ìš°ì„ ìˆœìœ„ - "low", "normal", "high" (ê¸°ë³¸ê°’: "normal")
- `async_mode`: ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: false)

> **ì°¸ê³ :** ì´ë¯¸ì§€ ìƒì„±ì€ `--model-type image-generation`ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì„œë²„ëŠ” MLX Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸(flux-schnell, flux-dev, flux-krea-dev), Qwen Image ëª¨ë¸(qwen-image), Z-Image Turbo(z-image-turbo), Fibo(fibo) ëª¨ë¸ì„ ì§€ì›í•˜ì—¬ êµ¬ì„± ê°€ëŠ¥í•œ í’ˆì§ˆ/ì†ë„ ê· í˜•ì„ ê°–ì¶˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

#### Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í¸ì§‘

```python
import openai
import base64
from io import BytesIO
from PIL import Image

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ê¸°ì¡´ ì´ë¯¸ì§€ í¸ì§‘
with open("images/china.png", "rb") as image_file:
    result = client.images.edit(
        image=image_file,
        prompt="make it like a photo in 1800s",
        model="flux-kontext-dev"
    )

# í¸ì§‘ëœ ì´ë¯¸ì§€ í‘œì‹œ
image_data = base64.b64decode(result.data[0].b64_json)
image = Image.open(BytesIO(image_data))
image.show()
```

#### ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ í¸ì§‘
```python
import requests

# ë” ë§ì€ ì œì–´ë¥¼ ìœ„í•´ ì–‘ì‹ ë°ì´í„°ì™€ í•¨ê»˜ ì§ì ‘ API í˜¸ì¶œ ì‚¬ìš©
with open("images/china.png", "rb") as image_file:
    files = {"image": image_file}
    data = {
        "prompt": "make it like a photo in 1800s",
        "model": "flux-kontext-dev",
        "negative_prompt": "modern, digital, high contrast",
        "guidance_scale": 2.5,
        "steps": 4,
        "seed": 42,
        "size": "1024x1024",
        "response_format": "b64_json"
    }
    
    response = requests.post(
        "http://localhost:8000/v1/images/edits",
        files=files,
        data=data,
        headers={"Authorization": "Bearer fake-api-key"}
    )

if response.status_code == 200:
    result = response.json()
    # base64 ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
    image_data = base64.b64decode(result['data'][0]['b64_json'])
    image = Image.open(BytesIO(image_data))
    image.show()
```

**ì´ë¯¸ì§€ í¸ì§‘ ë§¤ê°œë³€ìˆ˜:**
- `image`: í¸ì§‘í•  ì´ë¯¸ì§€ íŒŒì¼ (í•„ìˆ˜, PNG, JPEG ë˜ëŠ” JPG í˜•ì‹, ìµœëŒ€ 10MB)
- `prompt`: ì›í•˜ëŠ” í¸ì§‘ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª… (í•„ìˆ˜, ìµœëŒ€ 1000ì)
- `model`: ëª¨ë¸ ì‹ë³„ì (ê¸°ë³¸ê°’ "flux-kontext-dev")
- `negative_prompt`: í¸ì§‘ëœ ì´ë¯¸ì§€ì—ì„œ í”¼í•´ì•¼ í•  ê²ƒ (ì„ íƒ ì‚¬í•­)
- `guidance_scale`: ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ê°€ê¹ê²Œ ë”°ë¥¼ì§€ ì œì–´ (ê¸°ë³¸ê°’: flux-kontext-devì˜ ê²½ìš° 2.5, qwen-image-editì˜ ê²½ìš° 4.0)
- `steps`: ì¶”ë¡  ë‹¨ê³„ ìˆ˜, 1-50 (ê¸°ë³¸ê°’: flux-kontext-devì˜ ê²½ìš° 4, qwen-image-editì˜ ê²½ìš° 50)
- `seed`: ì¬í˜„ ê°€ëŠ¥í•œ í¸ì§‘ì„ ìœ„í•œ ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
- `size`: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° - "256x256", "512x512" ë˜ëŠ” "1024x1024" (ì„ íƒ ì‚¬í•­)
- `response_format`: ì‘ë‹µ í˜•ì‹ - "b64_json" (ê¸°ë³¸ê°’: "b64_json")

> **ì°¸ê³ :** ì´ë¯¸ì§€ í¸ì§‘ì€ `--model-type image-edit`ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì„œë²„ëŠ” MLX Flux ì‹œë¦¬ì¦ˆ ëª¨ë¸(flux-kontext-dev) ë° Qwen Image Edit ëª¨ë¸(qwen-image-edit)ì„ ì§€ì›í•˜ì—¬ êµ¬ì„± ê°€ëŠ¥í•œ í’ˆì§ˆ/ì†ë„ ê· í˜•ì„ ê°–ì¶˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ í¸ì§‘ì„ ì œê³µí•©ë‹ˆë‹¤.

#### í•¨ìˆ˜ í˜¸ì¶œ (Function Calling)
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ë©”ì‹œì§€ ë° ë„êµ¬ ì •ì˜
messages = [
    {
        "role": "user",
        "content": "What is the weather in Tokyo?"
    }
]

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get the weather in a given city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "The city to get the weather for"}
                }
            }
        }
    }
]

# API í˜¸ì¶œ ìˆ˜í–‰
completion = client.chat.completions.create(
    model="local-model",
    messages=messages,
    tools=tools,
    tool_choice="auto"
)

# ë„êµ¬ í˜¸ì¶œ ì‘ë‹µ ì²˜ë¦¬
if completion.choices[0].message.tool_calls:
    tool_call = completion.choices[0].message.tool_calls[0]
    print(f"Function called: {tool_call.function.name}")
    print(f"Arguments: {tool_call.function.arguments}")
    
    # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬ - ì¼ë°˜ì ìœ¼ë¡œ ì—¬ê¸°ì—ì„œ ì‹¤ì œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤
    # ì´ ì˜ˆì œì—ì„œëŠ” ë‚ ì”¨ ì‘ë‹µì„ í•˜ë“œì½”ë”©í•©ë‹ˆë‹¤
    weather_info = {"temperature": "22Â°C", "conditions": "Sunny", "humidity": "65%"}
    
    # ëŒ€í™”ì— ë„êµ¬ í˜¸ì¶œ ë° í•¨ìˆ˜ ì‘ë‹µ ì¶”ê°€
    messages.append(completion.choices[0].message)
    messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "name": tool_call.function.name,
        "content": str(weather_info)
    })
    
    # í•¨ìˆ˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê³„ì†
    final_response = client.chat.completions.create(
        model="local-model",
        messages=messages
    )
    print("\nFinal response:")
    print(final_response.choices[0].message.content)
```

#### JSON ìŠ¤í‚¤ë§ˆë¥¼ ì´ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ (Structured Outputs with JSON Schema)

ì„œë²„ëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì§€ì›í•˜ë¯€ë¡œ íŠ¹ì • JSON í˜•ì‹ì˜ ì‘ë‹µì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import openai
import json

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ë©”ì‹œì§€ ë° ì‘ë‹µ í˜•ì‹ ì •ì˜
messages = [
    {
        "role": "system",
        "content": "Extract the address from the user input into the specified JSON format."
    },
    {
        "role": "user",
        "content": "Please format this address: 1 Hacker Wy Menlo Park CA 94025"
    }
]

response_format = {
    "type": "json_schema",
    "json_schema": {
        "name": "Address",
        "schema": {
            "properties": {
                "address": {
                    "type": "object",
                    "properties": {
                        "street": {"type": "string"},
                        "city": {"type": "string"},
                        "state": {
                            "type": "string", 
                            "description": "2 letter abbreviation of the state"
                        },
                        "zip": {
                            "type": "string", 
                            "description": "5 digit zip code"
                        }
                    },
                    "required": ["street", "city", "state", "zip"]
                }
            },
            "required": ["address"],
            "type": "object"
        }
    }
}

# êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ API í˜¸ì¶œ ìˆ˜í–‰
completion = client.chat.completions.create(
    model="local-model",
    messages=messages,
    response_format=response_format
)

# êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹±
response_content = completion.choices[0].message.content
parsed_address = json.loads(response_content)
print("Structured Address:")
print(json.dumps(parsed_address, indent=2))
```

**ì‘ë‹µ í˜•ì‹ ë§¤ê°œë³€ìˆ˜:**
- `type`: êµ¬ì¡°í™”ëœ ì¶œë ¥ì˜ ê²½ìš° `"json_schema"`ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
- `json_schema`: ì˜ˆìƒë˜ëŠ” ì‘ë‹µ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” JSON ìŠ¤í‚¤ë§ˆ ê°ì²´
  - `name`: ìŠ¤í‚¤ë§ˆì˜ ì„ íƒì  ì´ë¦„
  - `schema`: ì†ì„±, ìœ í˜• ë° ìš”êµ¬ ì‚¬í•­ì´ í¬í•¨ëœ ì‹¤ì œ JSON ìŠ¤í‚¤ë§ˆ ì •ì˜

**ì‘ë‹µ ì˜ˆ:**
```json
{
  "address": {
    "street": "1 Hacker Wy",
    "city": "Menlo Park",
    "state": "CA",
    "zip": "94025"
  }
}
```

> **ì°¸ê³ :** êµ¬ì¡°í™”ëœ ì¶œë ¥ì€ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸(`--model-type lm`)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì œê³µëœ JSON ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.

#### ì„ë² ë”© (Embeddings)

1. í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ ì„ë² ë”©:
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
embedding_response = client.embeddings.create(
    model="mlx-community/DeepSeek-R1-Distill-Qwen-1.5B-MLX-Q8",
    input=["The quick brown fox jumps over the lazy dog"]
)
print(f"Embedding dimension: {len(embedding_response.data[0].embedding)}")

# ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
batch_response = client.embeddings.create(
    model="mlx-community/DeepSeek-R1-Distill-Qwen-1.5B-MLX-Q8",
    input=[
        "Machine learning algorithms improve with more data",
        "Natural language processing helps computers understand human language",
        "Computer vision allows machines to interpret visual information"
    ]
)
print(f"Number of embeddings: {len(batch_response.data)}")
```

2. ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì„ë² ë”©:
```python
import openai
import base64
from PIL import Image
from io import BytesIO

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

# ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def image_to_base64(image_path):
    image = Image.open(image_path)
    buffer = BytesIO()
    image.save(buffer, format="PNG")
    buffer.seek(0)
    image_data = buffer.getvalue()
    image_base64 = base64.b64encode(image_data).decode('utf-8')
    return f"data:image/png;base64,{image_base64}"

# ì´ë¯¸ì§€ ì¸ì½”ë”©
image_uri = image_to_base64("images/attention.png")

# í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
multimodal_embedding = client.embeddings.create(
    model="mlx-community/Qwen2.5-VL-3B-Instruct-4bit",
    input=["Describe the image in detail"],
    extra_body={"image_url": image_uri}
)
print(f"Multimodal embedding dimension: {len(multimodal_embedding.data[0].embedding)}")
```

> **ì°¸ê³ :** í•„ìš”ì— ë”°ë¼ ëª¨ë¸ ì´ë¦„ê³¼ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°”ê¾¸ì„¸ìš”. `extra_body` ë§¤ê°œë³€ìˆ˜ëŠ” ì´ë¯¸ì§€ ë°ì´í„° URIë¥¼ APIì— ì „ë‹¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

> **ê²½ê³ :** ë©€í‹°ëª¨ë‹¬ ìš”ì²­(ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤ í¬í•¨)ì„ í•  ë•ŒëŠ” ì„œë²„ê°€ `--model-type multimodal`ë¡œ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. `--model-type lm`(í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸)ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ì„œë²„ì— ë©€í‹°ëª¨ë‹¬ ìš”ì²­ì„ ë³´ë‚´ë©´ ë©€í‹°ëª¨ë‹¬ ìš”ì²­ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” 400 ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°›ê²Œ ë©ë‹ˆë‹¤.

## ìš”ì²­ ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ (Request Queue System)

ì„œë²„ëŠ” MLX ëª¨ë¸ ì¶”ë¡  ìš”ì²­ì„ ê´€ë¦¬í•˜ê³  ìµœì í™”í•˜ê¸° ìœ„í•´ ê°•ë ¥í•œ ìš”ì²­ ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ í™œìš©ê³¼ ê³µì •í•œ ìš”ì²­ ì²˜ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- **ë™ì‹œì„± ì œì–´**: ë¦¬ì†ŒìŠ¤ ê³ ê°ˆì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë™ì‹œ ëª¨ë¸ ì¶”ë¡  ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
- **ìš”ì²­ ëŒ€ê¸°ì—´**: ë³´ë¥˜ ì¤‘ì¸ ìš”ì²­ì— ëŒ€í•´ ê³µì •í•œ ì„ ì°©ìˆœ ëŒ€ê¸°ì—´ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ì‹œê°„ ì´ˆê³¼ ê´€ë¦¬**: êµ¬ì„±ëœ ì‹œê°„ ì´ˆê³¼ë¥¼ ì´ˆê³¼í•˜ëŠ” ìš”ì²­ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ëŒ€ê¸°ì—´ ìƒíƒœ ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜

ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œì€ ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. **RequestQueue**: ë‹¤ìŒì„ ìˆ˜í–‰í•˜ëŠ” ë¹„ë™ê¸° ëŒ€ê¸°ì—´ êµ¬í˜„ì²´ì…ë‹ˆë‹¤:
   - êµ¬ì„± ê°€ëŠ¥í•œ ëŒ€ê¸°ì—´ í¬ê¸°ë¡œ ë³´ë¥˜ ì¤‘ì¸ ìš”ì²­ ê´€ë¦¬
   - ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì‹¤í–‰ ì œì–´
   - ì‹œê°„ ì´ˆê³¼ ë° ì˜¤ë¥˜ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬
   - ì‹¤ì‹œê°„ ëŒ€ê¸°ì—´ í†µê³„ ì œê³µ

2. **ëª¨ë¸ í•¸ë“¤ëŸ¬**: ë‹¤ì–‘í•œ ëª¨ë¸ ìœ í˜•ì— ëŒ€í•œ íŠ¹ìˆ˜ í•¸ë“¤ëŸ¬:
   - `MLXLMHandler`: í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ ìš”ì²­ ê´€ë¦¬
   - `MLXVLMHandler`: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ìš”ì²­ ê´€ë¦¬
   - `MLXFluxHandler`: Flux ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ê´€ë¦¬

### ëŒ€ê¸°ì—´ ëª¨ë‹ˆí„°ë§

`/v1/queue/stats` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê¸°ì—´ í†µê³„ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤:

```bash
curl http://localhost:8000/v1/queue/stats
```

ì‘ë‹µ ì˜ˆ:
```json
{
  "status": "ok",
  "queue_stats": {
    "running": true,
    "queue_size": 3,
    "max_queue_size": 100,
    "active_requests": 5,
    "max_concurrency": 2
  }
}
```

### ì˜¤ë¥˜ ì²˜ë¦¬

ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œì€ ë‹¤ì–‘í•œ ì˜¤ë¥˜ ì¡°ê±´ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤:

1. **ëŒ€ê¸°ì—´ ê°€ë“ ì°¸ (429)**: ëŒ€ê¸°ì—´ì´ ìµœëŒ€ í¬ê¸°ì— ë„ë‹¬í–ˆì„ ë•Œ
```json
{
  "detail": "Too many requests. Service is at capacity."
}
```

2. **ìš”ì²­ ì‹œê°„ ì´ˆê³¼**: ìš”ì²­ì´ êµ¬ì„±ëœ ì‹œê°„ ì´ˆê³¼ë¥¼ ì´ˆê³¼í–ˆì„ ë•Œ
```json
{
  "detail": "Request processing timed out after 300 seconds"
}
```

3. **ëª¨ë¸ ì˜¤ë¥˜**: ëª¨ë¸ì´ ì¶”ë¡  ì¤‘ì— ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼°ì„ ë•Œ
```json
{
  "detail": "Failed to generate response: <error message>"
}
```

### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

ì„œë²„ëŠ” ì ì ˆí•œ ì²­í¬ í˜•ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì§€ì›í•©ë‹ˆë‹¤:
```python
{
    "id": "chatcmpl-1234567890",
    "object": "chat.completion.chunk",
    "created": 1234567890,
    "model": "local-model",
    "choices": [{
        "index": 0,
        "delta": {"content": "chunk of text"},
        "finish_reason": null
    }]
}
```

## API ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (API Response Schemas)

ì„œë²„ëŠ” ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ ì›í™œí•œ í†µí•©ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ OpenAI í˜¸í™˜ API ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ì£¼ìš” ì‘ë‹µ í˜•ì‹ì…ë‹ˆë‹¤:

### ì±„íŒ… ì™„ì„± ì‘ë‹µ (Chat Completions Response)

```json
{
  "id": "chatcmpl-123456789",
  "object": "chat.completion",
  "created": 1677858242,
  "model": "local-model",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "This is the response content from the model."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### ì„ë² ë”© ì‘ë‹µ (Embeddings Response)

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [0.001, 0.002, ..., 0.999],
      "index": 0
    }
  ],
  "model": "local-model",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

### í•¨ìˆ˜/ë„êµ¬ í˜¸ì¶œ ì‘ë‹µ (Function/Tool Calling Response)

```json
{
  "id": "chatcmpl-123456789",
  "object": "chat.completion",
  "created": 1677858242,
  "model": "local-model",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"city\":\"Tokyo\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 25,
    "total_tokens": 40
  }
}
```

### ì´ë¯¸ì§€ ìƒì„± ì‘ë‹µ (Image Generation Response)

```json
{
  "created": 1677858242,
  "data": [
    {
      "b64_json": "iVBORw0KGgoAAAANSUhEUgAA...",
      "url": null
    }
  ]
}
```

### ì˜¤ë¥˜ ì‘ë‹µ (Error Response)

```json
{
  "error": {
    "message": "Error message describing what went wrong",
    "type": "invalid_request_error",
    "param": null,
    "code": null
  }
}
```

## ì˜ˆì œ ë…¸íŠ¸ë¶ (Example Notebooks)

ì´ ì €ì¥ì†Œì—ëŠ” APIì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì˜ˆì œ ë…¸íŠ¸ë¶ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

- **function_calling_examples.ipynb**: ë¡œì»¬ ëª¨ë¸ì—ì„œ í•¨ìˆ˜ í˜¸ì¶œì„ êµ¬í˜„í•˜ê³  ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì‹¤ìš© ê°€ì´ë“œ:
  - í•¨ìˆ˜ ì •ì˜ ì„¤ì •
  - í•¨ìˆ˜ í˜¸ì¶œ ìš”ì²­ ìˆ˜í–‰
  - í•¨ìˆ˜ í˜¸ì¶œ ì‘ë‹µ ì²˜ë¦¬
  - ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ í˜¸ì¶œ ì‘ì—…
  - ë„êµ¬ ì‚¬ìš©ì„ í†µí•œ ë‹¤ì¤‘ í„´ ëŒ€í™” êµ¬ì¶•

- **structured_outputs_examples.ipynb**: JSON ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - JSON ìŠ¤í‚¤ë§ˆ ì •ì˜ ì„¤ì •
  - ì‘ë‹µ í˜•ì‹ ì‚¬ì–‘ìœ¼ë¡œ ìš”ì²­ ìˆ˜í–‰
  - êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹±
  - ë³µì¡í•œ ì¤‘ì²© ìŠ¤í‚¤ë§ˆ ì‘ì—…
  - êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì‚¬ìš©í•œ ë°ì´í„° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

- **vision_examples.ipynb**: APIì˜ ë¹„ì „ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬
  - ë¹„ì „ ë¶„ì„ ë° ê°ì²´ ê°ì§€
  - ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë‹¤ì¤‘ í„´ ëŒ€í™”
  - ìƒì„¸í•œ ì´ë¯¸ì§€ ì„¤ëª… ë° ë¶„ì„ì„ ìœ„í•œ ë¹„ì „ ëª¨ë¸ ì‚¬ìš©

- **lm_embeddings_examples.ipynb**: í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë¸ì„ ìœ„í•œ ì„ë² ë”© API ì‚¬ìš©ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - ë‹¨ì¼ ë° ë°°ì¹˜ ì…ë ¥ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
  - í…ìŠ¤íŠ¸ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ì„± ê³„ì‚°
  - ê°„ë‹¨í•œ ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•
  - ê°œë… ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ ë¹„êµ

- **vlm_embeddings_examples.ipynb**: Vision-Language Model ì„ë² ë”© ì‘ì—…ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œ:
  - í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
  - VLMìœ¼ë¡œ í…ìŠ¤íŠ¸ ì „ìš© ì„ë² ë”© ìƒì„±
  - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í‘œí˜„ ê°„ì˜ ìœ ì‚¬ì„± ê³„ì‚°
  - ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ê³µìœ  ì„ë² ë”© ê³µê°„ ì´í•´
  - VLM ì„ë² ë”©ì˜ ì‹¤ì œ ì ìš©

- **simple_rag_demo.ipynb**: ë¡œì»¬ MLX ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œì— ëŒ€í•œ ê²½ëŸ‰ RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš© ê°€ì´ë“œ:
  - PDF ë¬¸ì„œ ì½ê¸° ë° ì²­í‚¹
  - MLX ì„œë²„ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
  - ê²€ìƒ‰ì„ ìœ„í•œ ê°„ë‹¨í•œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
  - ê´€ë ¨ ì²­í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì§ˆë¬¸ ë‹µë³€ ìˆ˜í–‰
  - Qwen3 ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì„œ QAì˜ ì¢…ë‹¨ ê°„ ë°ëª¨
  <p align="center">
    <a href="https://youtu.be/ANUEZkmR-0s">
      <img src="https://img.youtube.com/vi/ANUEZkmR-0s/0.jpg" alt="RAG Demo" width="600">
    </a>
  </p>

- **audio_examples.ipynb**: MLX ì„œë²„ì˜ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê¸°ëŠ¥ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ MLX ì„œë²„ ì—°ê²° ì„¤ì •
  - API ì „ì†¡ì„ ìœ„í•œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ì¸ì½”ë”©
  - ë¶„ì„ì„ ìœ„í•´ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì— ì˜¤ë””ì˜¤ ì…ë ¥ ì „ì†¡
  - í’ë¶€í•˜ê³  ë¬¸ë§¥ì„ ì¸ì‹í•˜ëŠ” ì‘ë‹µì„ ìœ„í•´ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê²°í•©
  - ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì˜¤ë””ì˜¤ ë¶„ì„ í”„ë¡¬í”„íŠ¸ íƒìƒ‰
  - ì˜¤ë””ì˜¤ ì „ì‚¬ ë° ì½˜í…ì¸  ë¶„ì„ ê¸°ëŠ¥ ì´í•´

- **image_generations.ipynb**: MLX Flux ì‹œë¦¬ì¦ˆ ë° Qwen Image ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„±ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ MLX ì„œë²„ ì—°ê²° ì„¤ì •
  - ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±
  - ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜(ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸, ë‹¨ê³„, ì‹œë“œ)ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„±
  - ë‹¤ì–‘í•œ Flux êµ¬ì„±(schnell, dev, Krea-dev) ë° Qwen Image ëª¨ë¸ ì‘ì—…
  - ë¯¸ì„¸ ì¡°ì •ëœ ìƒì„±ì„ ìœ„í•œ LoRA ì–´ëŒ‘í„° ì‚¬ìš©
  - ì–‘ìí™” ì„¤ì •ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”

- **image_edit.ipynb**: MLX Flux ì‹œë¦¬ì¦ˆ ë° Qwen Image Edit ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í¸ì§‘ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì´ë“œ:
  - ì´ë¯¸ì§€ í¸ì§‘ì„ ìœ„í•œ MLX ì„œë²„ ì—°ê²° ì„¤ì •
  - ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ì´ë¯¸ì§€ í¸ì§‘
  - ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜(ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼, ë‹¨ê³„, ì‹œë“œ)ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ í¸ì§‘
  - ë¬¸ë§¥ í¸ì§‘ì„ ìœ„í•œ flux-kontext-dev ë° qwen-image-edit êµ¬ì„± ì‘ì—…
  - ë¯¸ì„¸ ì¡°ì •ëœ í¸ì§‘ì„ ìœ„í•œ LoRA ì–´ëŒ‘í„° ì‚¬ìš©
  - ìƒì„± ë° í¸ì§‘ ì›Œí¬í”Œë¡œìš° ê°„ì˜ ì°¨ì´ì  ì´í•´
  - íš¨ê³¼ì ì¸ ì´ë¯¸ì§€ í¸ì§‘ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•œ ëª¨ë²” ì‚¬ë¡€

## ëŒ€ê·œëª¨ ëª¨ë¸ (Large Models)
ì‹œìŠ¤í…œì˜ ì‚¬ìš© ê°€ëŠ¥í•œ RAMì— ë¹„í•´ í° ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. mlx-lmì€ ëª¨ë¸ê³¼ ìºì‹œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ ì™€ì´ì–´ë§(wiring)í•˜ì—¬ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¤ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ì´ ìµœì í™”ëŠ” macOS 15.0 ì´ìƒì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë§Œì•½ ë‹¤ìŒ ê²½ê³  ë©”ì‹œì§€ê°€ í‘œì‹œëœë‹¤ë©´:
> [WARNING] Generating with a model that requires ...
ëª¨ë¸ì´ ì»´í“¨í„°ì—ì„œ ëŠë¦¬ê²Œ ì‹¤í–‰ë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ëª¨ë¸ì´ RAMì— ë§ëŠ” ê²½ìš° ì‹œìŠ¤í…œì˜ ì™€ì´ì–´ë“œ ë©”ëª¨ë¦¬ ì œí•œì„ ë†’ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”:
```bash
bash configure_mlx.sh
```
## ë¼ì´ì„ ìŠ¤ (License)
ì´ í”„ë¡œì íŠ¸ëŠ” [MIT ë¼ì´ì„ ìŠ¤](LICENSE)ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤. ë¼ì´ì„ ìŠ¤ ì¡°ê±´ì— ë”°ë¼ ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì • ë° ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ—ï¸ í•µì‹¬ ê¸°ìˆ 
- **[MLX íŒ€](https://github.com/ml-explore/mlx)** - Apple Siliconì—ì„œ íš¨ìœ¨ì ì¸ ê¸°ê³„ í•™ìŠµì„ ìœ„í•œ ê¸°ë°˜ì„ ì œê³µí•˜ëŠ” íšê¸°ì ì¸ MLX í”„ë ˆì„ì›Œí¬ ê°œë°œ
- **[mlx-lm](https://github.com/ml-explore/mlx-lm)** - íš¨ìœ¨ì ì¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì§€ì› ë° ìµœì í™”
- **[mlx-vlm](https://github.com/Blaizzy/mlx-vlm/tree/main)** - MLX ìƒíƒœê³„ ë‚´ì—ì„œ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì§€ì› ê°œì²™
- **[mlx-embeddings](https://github.com/Blaizzy/mlx-embeddings)** - ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
- **[mflux](https://github.com/filipstrand/mflux)** - ê³ ê¸‰ êµ¬ì„±ì„ ê°–ì¶˜ Flux ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸
- **[mlx-whisper](https://github.com/ml-explore/mlx-examples/tree/main/whisper)** - Apple Siliconì—ì„œ ìµœì í™”ëœ ì¶”ë¡ ì„ í†µí•œ ì˜¤ë””ì˜¤ ì „ì‚¬ ë° ìŒì„± ì¸ì‹
- **[mlx-community](https://huggingface.co/mlx-community)** - ë‹¤ì–‘í•œ ê³ í’ˆì§ˆ MLX ëª¨ë¸ ì»¬ë ‰ì…˜ íë ˆì´íŒ… ë° ìœ ì§€ ê´€ë¦¬

